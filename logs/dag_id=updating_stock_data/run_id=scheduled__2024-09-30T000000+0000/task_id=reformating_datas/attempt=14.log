[2024-11-01T14:33:13.268+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: updating_stock_data.reformating_datas scheduled__2024-09-30T00:00:00+00:00 [queued]>
[2024-11-01T14:33:13.282+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: updating_stock_data.reformating_datas scheduled__2024-09-30T00:00:00+00:00 [queued]>
[2024-11-01T14:33:13.283+0000] {taskinstance.py:2193} INFO - Starting attempt 14 of 15
[2024-11-01T14:33:13.310+0000] {taskinstance.py:2217} INFO - Executing <Task(_PythonDecoratedOperator): reformating_datas> on 2024-09-30 00:00:00+00:00
[2024-11-01T14:33:13.316+0000] {standard_task_runner.py:60} INFO - Started process 2061 to run task
[2024-11-01T14:33:13.320+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'updating_stock_data', 'reformating_datas', 'scheduled__2024-09-30T00:00:00+00:00', '--job-id', '201', '--raw', '--subdir', 'DAGS_FOLDER/polars_postgres.py', '--cfg-path', '/tmp/tmpehfpez19']
[2024-11-01T14:33:13.321+0000] {standard_task_runner.py:88} INFO - Job 201: Subtask reformating_datas
[2024-11-01T14:33:13.381+0000] {task_command.py:423} INFO - Running <TaskInstance: updating_stock_data.reformating_datas scheduled__2024-09-30T00:00:00+00:00 [running]> on host 07e6c451f8a5
[2024-11-01T14:33:13.618+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow_development' AIRFLOW_CTX_DAG_ID='updating_stock_data' AIRFLOW_CTX_TASK_ID='reformating_datas' AIRFLOW_CTX_EXECUTION_DATE='2024-09-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='14' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-09-30T00:00:00+00:00'
[2024-11-01T14:33:13.633+0000] {python.py:202} INFO - Done. Returned value was: naive plan: (run LazyFrame.explain(optimized=True) to see the optimized plan)

FILTER [(col("Date")) >= (String(2024-10-02 14:33:13.620831))] FROM
  DF ["Date", "Open", "Close", "Low"]; PROJECT */5 COLUMNS; SELECTION: None
[2024-11-01T14:33:13.641+0000] {xcom.py:664} ERROR - Object of type bytes is not JSON serializable. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your airflow config or make sure to decorate your object with attr.
[2024-11-01T14:33:13.642+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/json.py", line 91, in default
    return serialize(o)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/serialization/serde.py", line 189, in serialize
    raise TypeError(f"cannot serialize object of type {cls}")
TypeError: cannot serialize object of type <class 'bytes'>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 451, in _execute_task
    task_instance.xcom_push(key=XCOM_RETURN_KEY, value=xcom_value, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 3013, in xcom_push
    XCom.set(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom.py", line 247, in set
    value = cls.serialize_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom.py", line 662, in serialize_value
    return json.dumps(value, cls=XComEncoder).encode("UTF-8")
  File "/usr/local/lib/python3.8/json/__init__.py", line 234, in dumps
    return cls(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/json.py", line 104, in encode
    return super().encode(o)
  File "/usr/local/lib/python3.8/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/local/lib/python3.8/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/json.py", line 93, in default
    return super().default(o)
  File "/usr/local/lib/python3.8/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type bytes is not JSON serializable
[2024-11-01T14:33:13.649+0000] {taskinstance.py:1149} INFO - Marking task as UP_FOR_RETRY. dag_id=updating_stock_data, task_id=reformating_datas, execution_date=20240930T000000, start_date=20241101T143313, end_date=20241101T143313
[2024-11-01T14:33:13.659+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 201 for task reformating_datas (Object of type bytes is not JSON serializable; 2061)
[2024-11-01T14:33:13.693+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-11-01T14:33:13.717+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
